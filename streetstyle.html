<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>AI algorithm analyzes millions of Instragram photos to measure global fashion trends - Atom to Atom</title>
		<link rel="stylesheet" type="text/css" href="articlestyle.css">

		<script>
		  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		  ga('create', 'UA-96173854-1', 'auto');
		  ga('send', 'pageview');

		</script>
	</head>

	<body>
		<header>
			<h1> Atom to Atom - a science and tech blog </h1>
			<h3> built from the ground up by <A href="bio.html">John C. Merfeld</A>.</h3>
		</header>

		<h3> <A href="index.html">return to homepage</A> </h3>

		<h1> 6/26/17 - AI algorithm analyzes millions of Instragram photos to measure global fashion trends </h1>

		<p> Researchers at Cornell University published a <A href="http://streetstyle.cs.cornell.edu/">paper</A> this month
			detailing the methodology and results of a computer analysis of over 100 million photos uploaded to Instagram over a three-year period.
			They were able to train algorithms to identify clothing styles in the photos and quantify how fashion trends vary throughout both space and time.</p>

		<p> Computer scientists <A href="http://kmatzen.com/">Kevin Matzen</A>, <A href="http://www.cs.cornell.edu/~kb/">Kavita Bala</A>, and <A href="http://www.cs.cornell.edu/~snavely/">Noah Snavely </A>, who utilized several machine learning techniques to create a first-of-its-kind analysis of global clothing styles, colors, and patterns, say their work represents a first step toward using machine learning and data mining techniques to gain insight into human culture. In particular, their aim is to tap the “tremendous cache of unstructured visual information… locked in images… including the billions of photos uploaded to photo-sharing services each day.” </p>

		<p> The broader strokes of the study’s findings can be viewed online using this <A href="http://streetstyle.cs.cornell.edu/trends.html">trend visualizer </A>. Queries to this tool demonstrate that some clothing trends are tied firmly to geography: people wearing jackets appeared in 54% of photos taken in Iceland, but only 6% of those in Jamaica. Other trends have more to do with the time of year: the frequency of the color red in the United States spikes around Halloween and Christmas (particularly red hats), and a similar red spike in China accompanies the Chinese New Year. </p>
		<p> The researchers selected clothing for their analysis because fashion offers an outward expression of multiple cultural factors: individuals may decide what to wear for reasons of geography, weather, religion, social status, gender expression, and beyond. These intersections of geography and culture played out in many different ways, showing that latitude was not necessarily destiny. For example, a country-by-country look at sleeveless shirts shows that people in Greece are twice as likely as those in neighboring (and more conservative) Turkey to go without sleeves. </p>
		<p> The study’s analytics also examined “styles,” or combination of clothing attributes, and measured to what degree they were concentrated in space or time (such as yellow sports Jerseys in Bogota, Colombia during the world cup), as opposed to being universal (such as blue collared shirts and black t-shirts worn around the world and throughout the year). </p>
		<p> An introductory selection of the algorithm’s findings is included in the following slides. You can use the <A href="http://streetstyle.cs.cornell.edu/trends.html">online trend analyzer</A> to find your own patterns in the data. Below, a more detailed discussion of the computational methodology is given.</p>

		<h2> Examples of results in trend visualizer </h2>

		<div class="slideshow-container">

			<div class="mySlides fade">
	  			<div class="numbertext-deep">1 / 5</div>
	  			<img src="usascarf.png" alt="for three straight years, scarves in the United States reached their maximum populartiy on the same week at the end of January" style="width:100%">
	  			<div class="text-top"> In the US, peak scarf popularity occurs on the same week at the end of January</div>
			</div>

			<div class="mySlides fade">
	  			<div class="numbertext-deep">2 / 5</div>
	  			<img src="sleeveless.png" alt="Sleevless shirts are most popular in Central America" style="width:100%">
	  			<div class="text-bottom">Sleevless shirts are most popular in Central America</div>
			</div>

			<div class="mySlides fade">
	  			<div class="numbertext-deep">3 / 5</div>
	  			<img src="plaid.png" alt="Plaid shirts are worn the most in Western Asia" style="width:100%">
	  			<div class="text-bottom">Despite its association with American hipsters, plaid is most commonly worn in Western Asia</div>
			</div>

			<div class="mySlides fade">
				<div class="numbertext-deep">4 / 5</div>
				<img src="red.png" alt="The color red appears to be on the decline" style="width:100%">
				<div class="text-top">Red has its seasonal spikes, but appears to be declining in global popularity</div>
			</div>

			<div class="mySlides fade">
				<div class="numbertext-deep">5 / 5</div>
				<img src="chicago.png" alt="The color red appears to be on the decline" style="width:100%">
				<div class="text-top">Red has its seasonal spikes, but appears to be declining in global popularity</div>
			</div>

			<a class="prev" onclick="plusSlides(-1)">&#10094;</a>
			<a class="next" onclick="plusSlides(1)">&#10095;</a>

		</div>
		<br>

		<div style="text-align:center">
	  		<span class="dot" onclick="currentSlide(1)"></span>
	  		<span class="dot" onclick="currentSlide(2)"></span>
	  		<span class="dot" onclick="currentSlide(3)"></span>
			<span class="dot" onclick="currentSlide(4)"></span>
			<span class="dot" onclick="currentSlide(5)"></span>

		</div>

		<script>
			var slideIndex = 1;
			showSlides(slideIndex);

			function plusSlides(n) {
		  		showSlides(slideIndex += n);
			}

			function currentSlide(n) {
		  		showSlides(slideIndex = n);
			}

			function showSlides(n) {
		  		var i;
		  		var slides = document.getElementsByClassName("mySlides");
		  		var dots = document.getElementsByClassName("dot");
		  		if (n > slides.length) {slideIndex = 1}
		  		if (n < 1) {slideIndex = slides.length}
		  		for (i = 0; i < slides.length; i++) {
		      		slides[i].style.display = "none";
		  		}
				  for (i = 0; i < dots.length; i++) {
				      dots[i].className = dots[i].className.replace(" active", "");
				  }
				  slides[slideIndex-1].style.display = "block";
				  dots[slideIndex-1].className += " active";
				}
		</script>

	<h2>Methodology </h2>

	<p> The two main types of machine learning are supervised and unsupervised learning; this study employs both techniques. Supervised learning requires having a set of “training data,” which is already sorted into the correct categories. The algorithm is exposed to this dataset so it can learn the distinguishing features of each category and then move on to unsorted data. During unsupervised learning, the algorithm is given an uncategorized dataset and is allowed to explore it and create its own categories and connections. </p>
	<p> The training data for this study were obtained by pulling over 100 million photos from the <A href="https://www.instagram.com/developer/">Instagram API</A>, which can query within five days of a specified date and within 5 kilometers of specified coordinates. From these, the facial recognition software <A href="https://www.faceplusplus.com/">Face++</A> was used to select the subset of photos that included a recognizable human face, around 37.7 million. Finally, a software tool called the “Deformable Part Model” allowed the researchers to select the subset of face photos in which a torso was also clearly visible (clothes on the lower body were not included, since the legs are often omitted from photos on social media). This left them with about 14.5 million photos. This is the dataset that would be explored during unsupervised learning, but the training dataset still needed to be generated. </p>
	<p> To generate the training data, Amazon’s <A href="https://www.mturk.com/mturk/welcome">Mechanical Turk </A> service was used to outsource the work of annotating clothing styles to human workers across the world, who were paid a few cents for every photo they analyzed. The end result was 27,000 annotated photos with distinct fashion characteristics. The researchers named this set STREETSTYLE-27K and have made it available online.</p>
	<p> During the supervised learning phase, a convolutional neural network (CNN) was used to classify the 14 million images not included in STREETSTYLE-27K. The basic function of a CNN is to map a high-dimensional input, such as the pixels of an image, to a lower-dimensional output, such as a yes-or-no answer to whether the person in that image is wearing a jacket. The CNN used in the study was trained on image recognition from other studies before being set loose on STREETSTYLE-27K on the other photos. </p>
	<div class="myfigure-big">
			<img src="style.png" alt="style clusters" ><br>Some examples of "style clusters" identified by the convolutional nueral network used in the Cornell study
	</div>
	<p> Finally, once the CNN had learned how to classify images, it was allowed to freely explore the dataset and generate its own connections. These explorations resulted in a set of “entropy diagrams,” essentially identifying correlations between fashion categories that constituted composite “style clusters,” and finding how concentrated these styles were in time and place. </p>
	<h3>Biases and future work </h3>
	<p> The study acknowledged many of the limitations in their ability to create a representative dataset of fashion trends. First of all, the use of images from Instagram necessarily biased the data toward areas where mobile internet is available and where Instagram is both popularly used and not censored by the government. The facial recognition software used in the study has not been tested for its own inherent biases of race, gender, and age, as <A href="https://www.theatlantic.com/technology/archive/2016/04/the-underlying-bias-of-facial-recognition-systems/476991/">have been reported </A> in other software.</p>
	<p> Quantifying and eliminating these biases are key to the researchers’ further work, according to the study. Strategies toward that end include gathering images from other sources, learning more about the biases of the facial recognition software, and even trying to distinguish between native inhabitants of a place and tourists visiting that place, who might skew the results. The researchers believe their analysis can be integrated with other information such as weather and social media activity to discovery new cultural connections around the world.</p>


	</body>
</html>
